# -*- coding: utf-8 -*-
"""Dataset_Preparation

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/priyanin/dataset-preparation.1965c769-f52d-416e-9c11-987aff04c837.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20251119/auto/storage/goog4_request%26X-Goog-Date%3D20251119T063158Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Db019810e8c81653e1b497eec7f77c5194c898d1849a81a087137e28b65286b1f5a1880c4cdeb90c4cad9574636a186a177d47ea6433987c69fea15a1bbc45f2432eb565469e97c599a070ede4ea80b260f19db02fcfb5928b4b41fc7c9358a235c923904cd6c3a8cf4befe3f4db45899760e5db9fc03f0269c3b73289a84ce1b3f5faf4fba6473650af8129c7e32bbf8116c5a6372216ea15a967598e535fba3a6fdb32a32d037ece9e84facb0333bf155d12b51426201ee27f5290bd849a03164304ef573b25782e463bfb9813a5cb6e65730cffb0c8f55ceda91f0725176933f70b0e8d79e2d3ef87a1b032bcc59a9b452e44982715613ba26f582ed7e76bd
"""
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms

# %% [code]
class CelebAMaskedDataset(Dataset):
    def __init__(self, root_dir, transform=None, mask_ratio=0.2, split="train", train_ratio=0.8, test_ratio=0.2, seed=42):
        assert split in ["train", "test"]
        
        self.root_dir = root_dir
        self.transform = transform
        self.mask_ratio = mask_ratio
        
        img_list = sorted(os.listdir(root_dir))

        np.random.seed(seed)
        np.random.shuffle(img_list)

        N = len(img_list)
        train_end = int(N * train_ratio)

        if split == "train":
            self.img_list = img_list[:train_end]
        else:
            self.img_list = img_list[train_end:]

    def __len__(self):
        return len(self.img_list)

    def __getitem__(self, idx):
        img_path = os.path.join(self.root_dir, self.img_list[idx])
        image = Image.open(img_path).convert("RGB")
        if self.transform:
            image = self.transform(image)
        mask = self.generate_mask(image.shape[1:], self.mask_ratio)
        mask = torch.from_numpy(mask).float().unsqueeze(0)
        masked_image = image * mask
        return masked_image, mask, image

    def generate_mask(self, size, ratio):
        H, W = size
        mask = np.ones((H, W), dtype=np.float32)
        num_mask = int(H * W * ratio)
        idx = np.random.choice(H*W, num_mask, replace=False)
        mask[np.unravel_index(idx, (H, W))] = 0.0
        return mask
